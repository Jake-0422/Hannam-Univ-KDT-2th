{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c28c61e",
   "metadata": {},
   "source": [
    "# 이미지 분야 딥러닝 모델"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d353d4e",
   "metadata": {},
   "source": [
    "## 1. CNN(Convolutional Neural Networks)\n",
    "##### : 이미지나 영상 데이터를 처리할 때 쓰이며 이름에서 알 수 있다시피 Convolution이라는 전처리 작업이 들어가는 Neural Network 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d492968",
   "metadata": {},
   "source": [
    "### CNN을 사용하는 이유\n",
    ": 이에 대한 답은 일반 DNN(Deep Neural Network)의 문제점에서부터 출발합니다. 일반 DNN은 기본적으로 1차원 형태의 데이터를 사용합니다. 때문에 (예를들면 1028x1028같은 2차원 형태의)이미지가 입력값이 되는 경우, 이것을 flatten시켜서 한줄 데이터로 만들어야 하는데 이 과정에서 이미지의 공간적/지역적 정보(spatial/topological information)가 손실되게 됩니다. 또한 추상화과정 없이 바로 연산과정으로 넘어가 버리기 때문에 학습시간과 능률의 효율성이 저하됩니다.\n",
    "\n",
    " 이러한 문제점에서부터 고안한 해결책이 CNN입니다. CNN은 이미지를 날것(raw input) 그대로 받음으로써 공간적/지역적 정보를 유지한 채 특성(feature)들의 계층을 빌드업합니다. CNN의 중요 포인트는 이미지 전체보다는 부분을 보는 것, 그리고 이미지의 한 픽셀과 주변 픽셀들의 연관성을 살리는 것입니다.\n",
    " \n",
    " 왜 CNN을 쓰는지 조금 더 쉽게 예를 들어 봅시다.\n",
    "\n",
    " 예를 들어 우리는 어떠한 이미지가 주어졌을때 이것이 새의 이미지인지 아닌지 결정할 수 있는 모델을 만들고 싶다고 가정합시다. 그렇다면 새의 주요 특징인 새의 부리가 중요한 포인트가 될 수 있습니다. 때문에 모델이 주어진 이미지에 새의 부리가 있는지 없는지 판가름 하는것이 중요 척도가 될 것입니다. 하지만 새의 전체 이미지에서 새의 부리 부분은 비교적 작은 부분입니다. 때문에 모델이 전체 이미지를 보는 것 보다는 새의 부리 부분을 잘라 보는게 더 효율적이겠죠? 그것을 해주는것이 CNN입니다. CNN의 뉴런이 패턴(이 경우에서는 새의 부리)을 파악하기 위해서 전체 이미지를 모두 다 볼 필요가 없습니다.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f1a54",
   "metadata": {},
   "source": [
    "## 2. YOLO(You Only Look Once)\n",
    "#### : 이미지를 한 번 보는 것만으로 Object의 종류와 위치를 추측하는 딥러닝 기반의 알고리즘\n",
    "\n",
    "### 소개\n",
    " : 사람은 어떤 이미지를 봤을때, 이미지 내부에 있는 Object들의 디테일을 한 눈에 파악할 수 있다. (Object가 무엇인지, 어디에 위치해있는지, 그들은 어떤 관계에 있는지 등) 적은 의식적 사고의 개입으로도 운전과 같은 복잡한 행위를 할 수 있는 이유도 여기에 있다. 허나, 근래의 R-CNN과 같은 detection system들은 복잡한 처리과정으로 인해 이러한 Human visual system을 모방하기에는 부족한 부분들을 보인다. (느린 속도, 최적화의 어려움)\n",
    "\n",
    " YOLO(You Only Look Once)는 이미지 내의 bounding box와 class probability를 single regression problem으로 간주하여, 이미지를 한 번 보는 것으로 object의 종류와 위치를 추측한다. 아래와 같이 single convolutional network를 통해 multiple bounding box에 대한 class probablility를 계산하는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca115374",
   "metadata": {},
   "source": [
    "### YOLO의 감지 시스템\n",
    "\n",
    "> (1) **Input image**를 **resize**한다.\n",
    "\n",
    "> (2) image에서 작동하는 **single convolutional network(1 x 1 convolutions)를 실행**한다.\n",
    "\n",
    "> (3) 해당 모델을 통해서 나온 **확률값**을 **threshold로 잘라서 결과값을 보여준다.**(object 점수를 기준으로 box를 필터링하고 일반적으로 점수가 threshold 미만인 box는 무시된다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df01e96",
   "metadata": {},
   "source": [
    "## 장점\n",
    "#### : 1-stage detector로서 간단한 처리과정으로 다른 딥러닝 알고리즘에 비해 **속도가 매우 빠르며, 높은 mAP(mean Average Precision)을 보입니다.**\n",
    "\n",
    "> **(1) YOLO는 매우 빠릅니다.**\n",
    "> - 복잡한 pipeline이 필요하지 않으며 **이미지에 neural network를 실행하기만 하면 됩니다.**\n",
    "> - **다른 실시간 객체 탐지 방법보다 mAP(mean Average Precision)가 2배 이상 높습니다.**\n",
    "\n",
    "> **(2) Fast R-CNN보다 background error(배경 이미지에 객체가 있다고 탐지한 것)가 두 배 이상 적습니다.**\n",
    "> - **YOLO는 예측할 때, 이미지 전체를 이용합니다. 이 덕분에 class와 객체출현에 대한 contextual information까지 이용할 수 있습니다.**\n",
    "> - 반면 Fast R-CNN은 selective search가 제안한 영역만을 이용하여 예측하기 때문에 larger context를 이용하지 못합니다.\n",
    "> - 따라서 R-CNN은 배경을 객체로 탐지하는 실수르 하게 됩니다.\n",
    "\n",
    "> **(3) YOLO는 객체에 대한 일반화를 학습합니다.**\n",
    "> - 예를 들어, natural image로 학습하고 artwork로 테스트 했을 때, DPM이나 R-CNN과 같은 top detection method보다 더 높은 성능을 보여줍니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed7990",
   "metadata": {},
   "source": [
    "## 단점\n",
    "> (1) **작은 object**에 대해서 상대적으로 **낮은 정확도를 보입니다.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
